{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eff7bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, f1_score,precision_score\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01f7f9f",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "202278e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('final_x_train.csv')\n",
    "y_train = pd.read_csv('final_y_train.csv')\n",
    "x_valid = pd.read_csv('final_x_valid.csv')\n",
    "y_valid = pd.read_csv('final_y_valid.csv')\n",
    "x_test = pd.read_csv('final_x_test.csv')\n",
    "y_test = pd.read_csv('final_y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4833885e",
   "metadata": {},
   "source": [
    "## Set up models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b06bf5",
   "metadata": {},
   "source": [
    "Applied all methods in both one-vs-one and one-vs-rest. Then, we will compare their performance with the original methods based on their accuracy rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70f000d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Orign_ModeL(model):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_valid)\n",
    "    f1 = f1_score(y_valid, y_pred, average='micro')\n",
    "    precision = precision_score(y_valid, y_pred, average='micro')\n",
    "    recall = recall_score(y_valid, y_pred, average='micro')\n",
    "    print(f\"precision score: {precision:.4f}, recall score: {recall:.4f}, f1 score: {f1:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9c0eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OVO_Model(model):\n",
    "    OVOmodel = OneVsOneClassifier(model)\n",
    "    OVOmodel.fit(x_train, y_train)\n",
    "    y_pred = OVOmodel.predict(x_valid)\n",
    "    f1 = f1_score(y_valid, y_pred, average='micro')\n",
    "    precision = precision_score(y_valid, y_pred, average='micro')\n",
    "    recall = recall_score(y_valid, y_pred, average='micro')\n",
    "    print(f\"precision score: {precision:.4f}, recall score: {recall:.4f}, f1 score: {f1:.4f}\")\n",
    "    return OVOmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d533ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OVR_Model(model):\n",
    "    OVRmodel = OneVsRestClassifier(model)\n",
    "    OVRmodel.fit(x_train, y_train)\n",
    "    y_pred = OVRmodel.predict(x_valid)\n",
    "    f1 = f1_score(y_valid, y_pred, average='micro')\n",
    "    precision = precision_score(y_valid, y_pred, average='micro')\n",
    "    recall = recall_score(y_valid, y_pred, average='micro')\n",
    "    print(f\"precision score: {precision:.4f}, recall score: {recall:.4f}, f1 score: {f1:.4f}\")\n",
    "    return OVRmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41e0f325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "y_vaild1 = y_valid.copy()\n",
    "y_train1 = y_train.copy()\n",
    "y_test1 = y_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc49bbe",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82083e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score: 0.0114, recall score: 0.0114, f1 score: 0.0114\n",
      "precision score: 0.0114, recall score: 0.0114, f1 score: 0.0114\n",
      "precision score: 0.0143, recall score: 0.0143, f1 score: 0.0143\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "NBOM =Orign_ModeL(GaussianNB())\n",
    "NBOVO=OVO_Model(GaussianNB())\n",
    "NBOVR=OVR_Model(GaussianNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01a8441f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score: 0.1701, recall score: 0.1701, f1 score: 0.1701\n",
      "precision score: 0.1929, recall score: 0.1929, f1 score: 0.1929\n",
      "precision score: 0.1649, recall score: 0.1649, f1 score: 0.1649\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "KNNOM =Orign_ModeL(KNeighborsClassifier())\n",
    "KNNOVO=OVO_Model(KNeighborsClassifier())\n",
    "KNNOVR=OVR_Model(KNeighborsClassifier()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cd90e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a9958\\AppData\\Local\\Temp\\ipykernel_13240\\3920633701.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(x_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score: 0.2231, recall score: 0.2231, f1 score: 0.2231\n",
      "precision score: 0.2176, recall score: 0.2176, f1 score: 0.2176\n",
      "precision score: 0.2154, recall score: 0.2154, f1 score: 0.2154\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "RFOM =Orign_ModeL(RandomForestClassifier())\n",
    "RFOVO=OVO_Model(RandomForestClassifier())\n",
    "RFOVR=OVR_Model(RandomForestClassifier()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e08ed5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score: 0.2088, recall score: 0.2088, f1 score: 0.2088\n",
      "precision score: 0.2149, recall score: 0.2149, f1 score: 0.2149\n",
      "precision score: 0.2208, recall score: 0.2208, f1 score: 0.2208\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_valid = le.fit_transform(y_valid)\n",
    "XGBOM =Orign_ModeL(XGBClassifier())\n",
    "XGBOVO=OVO_Model(XGBClassifier())\n",
    "XGBOVR=OVR_Model(XGBClassifier()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c435d59a",
   "metadata": {},
   "source": [
    "## Model improving "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae49e79",
   "metadata": {},
   "source": [
    "To improve accuracy, you can utilize the GridSearchCV package and loops to compare different hyperparameters and select the best configuration for better performance. Those approach will be employed for both Random Forest and XGBoost algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4625ea5b",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34d16f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 750 candidates, totalling 3750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a9958\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:926: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(bootstrap=False, max_depth=10, max_leaf_nodes=25,\n",
       "                        min_samples_split=10, random_state=0),\n",
       " {'bootstrap': False,\n",
       "  'max_depth': 10,\n",
       "  'max_leaf_nodes': 25,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_samples_split': 10},\n",
       " 0.22136916186820219)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setup a empty dict to save the best hyperparameters for future model improvemnt\n",
    "parameters = {}\n",
    "\n",
    "# First, trying to find the best hyperparameters in bootstrap, max depth, min samples split, \n",
    "# min samples split, max leaf nodes, and min samples leaf\n",
    "param_grid = {\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"max_depth\": range(5, 30, 5),\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"max_leaf_nodes\": range(5, 55, 10),\n",
    "    \"min_samples_leaf\": range(1, 11, 2)\n",
    "}\n",
    "\n",
    "Hyper_param_search = GridSearchCV(estimator=RandomForestClassifier(random_state=0),\n",
    "                       param_grid=param_grid, scoring='f1_micro', n_jobs=8, cv=5, verbose=2.5)\n",
    "Hyper_param_search.fit(x_train, y_train1)\n",
    "\n",
    "# Update the best hyperparameter to the parameters dict\n",
    "parameters.update(Hyper_param_search.best_params_)\n",
    "Hyper_param_search.best_estimator_, Hyper_param_search.best_params_, Hyper_param_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dca4e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a9958\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:926: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(bootstrap=False, max_depth=10, max_features='sqrt',\n",
       "                        max_leaf_nodes=25, min_samples_split=10, random_state=0),\n",
       " {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 100},\n",
       " 0.22136916186820219)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Secondly, trying to find the best hyperparameters in n estimators, max features , and criterion.\n",
    "# Also, apply the best hyperparameters from last result\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 500, 1000],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "Hyper_param_search = GridSearchCV(estimator=RandomForestClassifier(**parameters, random_state=0),\n",
    "                       param_grid=param_grid, scoring='f1_micro', n_jobs=8, cv=5, verbose=2.5,error_score='raise')\n",
    "Hyper_param_search.fit(x_train, y_train1)\n",
    "parameters.update(Hyper_param_search.best_params_)\n",
    "Hyper_param_search.best_estimator_, Hyper_param_search.best_params_, Hyper_param_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70b90ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# employed the best hyperparameters from previous result to baseline model, \n",
    "# One Vs One model and One Vs Rest model\n",
    "Classifier = RandomForestClassifier(**parameters,random_state=0)\n",
    "OvO = OneVsOneClassifier(RandomForestClassifier(**parameters,random_state=0))\n",
    "OVR =OneVsRestClassifier(RandomForestClassifier(**parameters,random_state=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89572429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a9958\\AppData\\Local\\Temp\\ipykernel_13240\\2617743496.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  Classifier.fit(x_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Ove Vs One, precision score: 0.2354, recall score: 0.2354, f1 score: 0.2354\n",
      "For Ove Vs One, precision score: 0.2201, recall score: 0.2201, f1 score: 0.2201\n",
      "For Ove vs Rest, precision score: 0.2236, recall score: 0.2236, f1 score: 0.2236\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation by test set\n",
    "\n",
    "#Baseline \n",
    "Classifier.fit(x_train,y_train)\n",
    "y_pred = Classifier.predict(x_test)\n",
    "f1 = f1_score(y_test1, y_pred, average='micro')\n",
    "precision = precision_score(y_test, y_pred, average='micro')\n",
    "recall = recall_score(y_test1, y_pred, average='micro')\n",
    "print(f\"For orignal method, precision score: {precision:.4f}, recall score: {recall:.4f}, f1 score: {f1:.4f}\")\n",
    "\n",
    "# One-Vs-One\n",
    "OvO.fit(x_train,y_train)\n",
    "y_pred = OvO.predict(x_test)\n",
    "f1 = f1_score(y_test1, y_pred, average='micro')\n",
    "precision = precision_score(y_test, y_pred, average='micro')\n",
    "recall = recall_score(y_test1, y_pred, average='micro')\n",
    "print(f\"For Ove Vs One, precision score: {precision:.4f}, recall score: {recall:.4f}, f1 score: {f1:.4f}\")\n",
    "\n",
    "# One-Vs-Rest\n",
    "OVR.fit(x_train,y_train)\n",
    "y_pred = OVR.predict(x_test)\n",
    "f1 = f1_score(y_test1, y_pred, average='micro')\n",
    "precision = precision_score(y_test1, y_pred, average='micro')\n",
    "recall = recall_score(y_test1, y_pred, average='micro')\n",
    "print(f\"For Ove vs Rest, precision score: {precision:.4f}, recall score: {recall:.4f}, f1 score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c6450",
   "metadata": {},
   "source": [
    "##### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14afa421",
   "metadata": {},
   "source": [
    "In conclusion, after implementing various improvements, it was observed that the baseline method achieved the highest F1 score of 0.2354 for the Random Forest algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8bcbc2",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21674bb7",
   "metadata": {},
   "source": [
    "Utilizing a loop to discover optimal hyperparameters for max depth, gamma, and reg alpha, while concurrently maintaining a dataframe to log each selected hyperparameter and its corresponding accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14354d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used to search the best result\n",
    "def best_result(df):\n",
    "    max_index = df['f1_score'].idxmax()\n",
    "    max_row = df.loc[max_index]\n",
    "    return max_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d65db127",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [3,4,5]\n",
    "gamma = [0,0.1,0.2,0.3,0.4,0.5]\n",
    "reg_alpha = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "conclusion = pd.DataFrame(columns=['max_depth', 'gamma', 'reg_alpha','f1_score'])\n",
    "\n",
    "# Baseline \n",
    "for i in max_depth:\n",
    "    for j in gamma:\n",
    "        for k in reg_alpha:\n",
    "            model = XGBClassifier(max_depth = i, gamma = j, reg_alpha = k,learning_rate=0.1, nthread=8, random_state=0)\n",
    "            model.fit(x_train, y_train)\n",
    "            y_pred = model.predict(x_valid)\n",
    "            f1 = f1_score(y_valid, y_pred, average='micro')\n",
    "            data = {'max_depth':i, 'gamma':j, 'reg_alpha':k,'f1_score': round(f1*100,4)}\n",
    "            conclusion = pd.concat([conclusion, pd.DataFrame([data])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90b513eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_depth          4\n",
       "gamma            0.2\n",
       "reg_alpha        1.0\n",
       "f1_score     22.6291\n",
       "Name: 52, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result(conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe5e9cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using one-vs-one method \n",
    "conclusion1 = pd.DataFrame(columns=['max_depth', 'gamma', 'reg_alpha','f1_score'])\n",
    "\n",
    "for i in max_depth:\n",
    "    for j in gamma:\n",
    "        for k in reg_alpha:\n",
    "            model = OneVsOneClassifier(XGBClassifier(max_depth = i, gamma = j, reg_alpha = k,learning_rate=0.1, nthread=8, random_state=0))\n",
    "            model.fit(x_train, y_train)\n",
    "            y_pred = model.predict(x_valid)\n",
    "            f1 = f1_score(y_valid, y_pred, average='micro')\n",
    "            data = {'max_depth':i, 'gamma':j, 'reg_alpha':k,'f1_score': round(f1*100,4)}\n",
    "            conclusion1 = pd.concat([conclusion, pd.DataFrame([data])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a8d0c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_depth          4\n",
       "gamma            0.2\n",
       "reg_alpha        1.0\n",
       "f1_score     22.6291\n",
       "Name: 52, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result(conclusion1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c47ad998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using one-vs-rest method \n",
    "conclusion2 = pd.DataFrame(columns=['max_depth', 'gamma', 'reg_alpha','f1_score'])\n",
    "\n",
    "for i in max_depth:\n",
    "    for j in gamma:\n",
    "        for k in reg_alpha:\n",
    "            model = OneVsRestClassifier(XGBClassifier(max_depth = i, gamma = j, reg_alpha = k,learning_rate=0.1, nthread=8, random_state=0))\n",
    "            model.fit(x_train, y_train)\n",
    "            y_pred = model.predict(x_valid)\n",
    "            f1 = f1_score(y_valid, y_pred, average='micro')\n",
    "            data = {'max_depth':i, 'gamma':j, 'reg_alpha':k,'f1_score': round(f1*100,4)}\n",
    "            conclusion2 = pd.concat([conclusion, pd.DataFrame([data])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6d221d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_depth          5\n",
       "gamma            0.5\n",
       "reg_alpha       10.0\n",
       "f1_score     22.9702\n",
       "Name: 108, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result(conclusion2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffa56285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score: 0.2165, recall score: 0.2165, f1 score: 0.2165\n",
      "precision score: 0.2078, recall score: 0.2078, f1 score: 0.2078\n",
      "precision score: 0.2272, recall score: 0.2272, f1 score: 0.2272\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation by test set\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "#Baseline \n",
    "model = XGBClassifier(max_depth = 4, gamma = 0.2, reg_alpha = 1 ,learning_rate=0.1, nthread=8, random_state=0)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "precision = precision_score(y_test, y_pred, average='micro')\n",
    "recall = recall_score(y_test, y_pred, average='micro')\n",
    "print(f\"precision score: {precision:.4f}, recall score: {recall:.4f}, f1 score: {f1:.4f}\")\n",
    "\n",
    "#One-VS-One\n",
    "OVOmodel = OneVsOneClassifier(XGBClassifier(max_depth = 4, gamma = 0.2, reg_alpha = 1 ,learning_rate=0.1, nthread=8, random_state=0))\n",
    "OVOmodel.fit(x_train, y_train)\n",
    "y_pred = OVOmodel.predict(x_test)\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "precision = precision_score(y_test, y_pred, average='micro')\n",
    "recall = recall_score(y_test, y_pred, average='micro')\n",
    "print(f\"precision score: {precision:.4f}, recall score: {recall:.4f}, f1 score: {f1:.4f}\")\n",
    "\n",
    "#One-Vs-Rest\n",
    "OVRmodel = OneVsRestClassifier(XGBClassifier(max_depth = 5, gamma = 0.5, reg_alpha = 10 ,learning_rate=0.1, nthread=8, random_state=0))\n",
    "OVRmodel.fit(x_train, y_train)\n",
    "y_pred = OVRmodel.predict(x_test)\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "precision = precision_score(y_test, y_pred, average='micro')\n",
    "recall = recall_score(y_test, y_pred, average='micro')\n",
    "print(f\"precision score: {precision:.4f}, recall score: {recall:.4f}, f1 score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f02e674",
   "metadata": {},
   "source": [
    "##### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0440b30",
   "metadata": {},
   "source": [
    "In conclusion, after implementing various improvements, it was observed that the one-vs-rest method achieved the highest F1 score of 0.2272 for the XGBoost algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
